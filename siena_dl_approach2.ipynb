{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNKoNAyR1Xyq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Function\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meta_data = np.load(\"clinical_metadata.npy\")\n",
        "labels = np.load(\"labels.npy\")\n",
        "\n",
        "with open(\"patient_id_encoder (1).pkl\", \"rb\") as f:\n",
        "    patient_ids = np.array(pickle.load(f))\n",
        "#Set file path\n",
        "eeg_files = np.load(\"eeg_file_paths.npy\", allow_pickle=True)\n",
        "\n",
        "unique_pids = np.unique(patient_ids)\n"
      ],
      "metadata": {
        "id": "j_dJtuEE1bxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Load dataset"
      ],
      "metadata": {
        "id": "oh_SrY0a1vSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGDataset(Dataset):\n",
        "    def __init__(self, eeg_files, meta, labels, pids):\n",
        "        self.eeg_files = eeg_files\n",
        "        self.meta = meta\n",
        "        self.labels = labels\n",
        "        self.pids = pids\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.eeg_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        eeg = np.load(self.eeg_files[idx])[\"eeg\"]\n",
        "        eeg = torch.tensor(eeg, dtype=torch.float32)\n",
        "\n",
        "        meta = torch.tensor(self.meta[idx], dtype=torch.float32)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        pid = torch.tensor(self.pids[idx], dtype=torch.long)\n",
        "\n",
        "        return eeg, meta, label, pid\n"
      ],
      "metadata": {
        "id": "gEx4jQsJ1sp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient reversal for domain adaptation"
      ],
      "metadata": {
        "id": "Q4gUTc3s11UK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GradReverse(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        return -ctx.alpha * grad_output, None\n"
      ],
      "metadata": {
        "id": "QGgXIxCP10C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN feature extractor"
      ],
      "metadata": {
        "id": "KRoStiqf14IQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EEGCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, (3,7), padding=(1,3)),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((1,2)),\n",
        "\n",
        "            nn.Conv2d(32, 64, (3,5), padding=(1,2)),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d((1,1))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.net(x)\n",
        "        return x.squeeze(-1).squeeze(-1)\n"
      ],
      "metadata": {
        "id": "BCa1xkgk161i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention Pooling"
      ],
      "metadata": {
        "id": "Ci-8lClN19PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionPooling(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Sequential(\n",
        "            nn.Linear(dim, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        weights = torch.softmax(self.attn(x), dim=1)\n",
        "        return (x * weights).sum(dim=1)\n"
      ],
      "metadata": {
        "id": "A8zbHXSp2JRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiled CNN-BiLSTM model with attention"
      ],
      "metadata": {
        "id": "fu0ntUM82KPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EpilepsyNet(nn.Module):\n",
        "    def __init__(self, meta_dim, num_domains):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cnn = EEGCNN()\n",
        "        self.lstm = nn.LSTM(64, 128, bidirectional=True, batch_first=True)\n",
        "        self.attn = AttentionPooling(256)\n",
        "\n",
        "        self.meta_fc = nn.Sequential(\n",
        "            nn.Linear(meta_dim, 32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 + 32, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "        self.domain = nn.Sequential(\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_domains)\n",
        "        )\n",
        "\n",
        "    def forward(self, eeg, meta, alpha=0.0):\n",
        "        B, W, C, T = eeg.shape\n",
        "\n",
        "        x = eeg.view(B*W, C, T)\n",
        "        x = self.cnn(x)\n",
        "        x = x.view(B, W, -1)\n",
        "\n",
        "        x, _ = self.lstm(x)\n",
        "        eeg_embed = self.attn(x)\n",
        "\n",
        "        meta_embed = self.meta_fc(meta)\n",
        "        fused = torch.cat([eeg_embed, meta_embed], dim=1)\n",
        "\n",
        "        cls_out = self.classifier(fused)\n",
        "        dom_out = self.domain(GradReverse.apply(eeg_embed, alpha))\n",
        "\n",
        "        return cls_out, dom_out\n"
      ],
      "metadata": {
        "id": "SaH8a-Eg2OcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOPO training"
      ],
      "metadata": {
        "id": "-8TtR2Fz2T9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_lopo():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    dataset = EEGDataset(eeg_files, meta_data, labels, patient_ids)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for test_pid in unique_pids:\n",
        "\n",
        "        train_idx = np.where(patient_ids != test_pid)[0]\n",
        "        test_idx = np.where(patient_ids == test_pid)[0]\n",
        "\n",
        "        train_ds = torch.utils.data.Subset(dataset, train_idx)\n",
        "        test_ds = torch.utils.data.Subset(dataset, test_idx)\n",
        "\n",
        "        train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
        "        test_loader = DataLoader(test_ds, batch_size=1)\n",
        "\n",
        "        model = EpilepsyNet(\n",
        "            meta_dim=meta_data.shape[1],\n",
        "            num_domains=len(unique_pids)\n",
        "        ).to(device)\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(40):\n",
        "            model.train()\n",
        "            alpha = min(1.0, epoch / 20)\n",
        "\n",
        "            for eeg, meta, label, pid in train_loader:\n",
        "                eeg, meta = eeg.to(device), meta.to(device)\n",
        "                label, pid = label.to(device), pid.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                cls, dom = model(eeg, meta, alpha)\n",
        "                loss = loss_fn(cls, label) + 0.2 * loss_fn(dom, pid)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for eeg, meta, _, _ in test_loader:\n",
        "                eeg, meta = eeg.to(device), meta.to(device)\n",
        "                out, _ = model(eeg, meta)\n",
        "                probs.append(torch.softmax(out, 1)[0,1].item())\n",
        "\n",
        "        pred = int(np.mean(probs) > 0.5)\n",
        "        true = labels[test_idx[0]]\n",
        "\n",
        "        results.append(pred == true)\n",
        "\n",
        "    print(\"Final LOPO Accuracy:\", np.mean(results))\n"
      ],
      "metadata": {
        "id": "C1IiB4512QzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run LOPO"
      ],
      "metadata": {
        "id": "73UwjLFT2ZHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_lopo()\n"
      ],
      "metadata": {
        "id": "_5BKFnsB2XGh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}